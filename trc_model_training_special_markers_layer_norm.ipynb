{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(os.getcwd()), \".\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from trc_model.temporal_relation_classification import TemporalRelationClassification\n",
    "from trc_model.temporal_relation_classification_config import TemporalRelationClassificationConfig\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding, AutoTokenizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weights(dataset):\n",
    "    labels = dataset['train']['label']\n",
    "    labels_count = Counter(labels)\n",
    "    class_weights = [0] * len(labels_count)\n",
    "    for l, count in labels_count.items():\n",
    "        cls_w = 1 - (count / len(labels))\n",
    "        class_weights[l] = cls_w\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_mode = False\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    predictions, labels = eval_preds\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    if eval_mode:\n",
    "        report = classification_report(y_true=labels, y_pred=predictions,\n",
    "                                       target_names=['BEFORE', 'AFTER', 'EQUAL', 'VAGUE'])\n",
    "        for i in range(labels.shape[0]):\n",
    "            if labels[i] == 3 and predictions[i] != 3:\n",
    "                labels[i] = predictions[i]\n",
    "        report_no_vague = classification_report(y_true=labels, y_pred=predictions,\n",
    "                                                target_names=['BEFORE', 'AFTER', 'EQUAL', 'VAGUE'])\n",
    "\n",
    "        with open(f'{model_final_name}/evaluation_report.txt', 'w') as f:\n",
    "            f.write(report)\n",
    "            f.write('\\n')\n",
    "            f.write(report_no_vague)\n",
    "        print(report)\n",
    "        print(report_no_vague)\n",
    "\n",
    "    results = \\\n",
    "        classification_report(y_true=labels, y_pred=predictions, target_names=['BEFORE', 'AFTER', 'EQUAL', 'VAGUE'],\n",
    "                              output_dict=True)\n",
    "    final_results = results['weighted avg']\n",
    "    final_results.pop('support')\n",
    "    final_results['BEFORE-f1'] = results['BEFORE']['f1-score']\n",
    "    final_results['AFTER-f1'] = results['AFTER']['f1-score']\n",
    "    final_results['EQUAL-f1'] = results['EQUAL']['f1-score']\n",
    "    final_results['VAGUE-f1'] = results['VAGUE']['f1-score']\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_checkpoints = ['imvladikon/alephbertgimmel-base-512', 'bert-base-multilingual-cased']\n",
    "architectures = ['ESS', 'EMP', 'SEQ_CLS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = load_dataset(f\"data_handling/data_splits/split_3\")\n",
    "label2id = {}\n",
    "id2label = {}\n",
    "for label, named_label in zip(raw_datasets['train']['label'], raw_datasets['train']['named_label']):\n",
    "    label2id[named_label] = label\n",
    "    id2label[label] = named_label\n",
    "\n",
    "class_weights = calculate_class_weights(raw_datasets)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for checkpoint in lm_checkpoints:\n",
    "    for arc in architectures:\n",
    "        model_base_name = checkpoint.split(\"/\")[1] if \"/\" in checkpoint else checkpoint\n",
    "        model_final_name = f'hebrew-trc-{model_base_name}-{arc}'\n",
    "        tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "        tokenizer.add_special_tokens({'additional_special_tokens': ['[א1]', '[/א1]', '[א2]', '[/א2]']})\n",
    "        E1_start = tokenizer.convert_tokens_to_ids('[א1]')\n",
    "        E1_end = tokenizer.convert_tokens_to_ids('[/א1]')\n",
    "        E2_start = tokenizer.convert_tokens_to_ids('[א2]')\n",
    "        E2_end = tokenizer.convert_tokens_to_ids('[/א2]')\n",
    "        tokenized_datasets = raw_datasets.map(preprocess_function, remove_columns=['named_label'], batched=True)\n",
    "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "        tokenizer_class = str(type(tokenizer)).strip(\"><'\").split('.')[-1]\n",
    "        config = TemporalRelationClassificationConfig(EMS1=E1_start,\n",
    "                                                      EMS2=E2_start,\n",
    "                                                      EME1=E1_end,\n",
    "                                                      EME2=E2_end,\n",
    "                                                      class_weights=class_weights,\n",
    "                                                      architecture=arc,\n",
    "                                                      num_labels=len(label2id),\n",
    "                                                      id2label=id2label,\n",
    "                                                      label2id=label2id,\n",
    "                                                      name_or_path=checkpoint,\n",
    "                                                      tokenizer_class=tokenizer_class,\n",
    "                                                      vocab_size=len(tokenizer))\n",
    "\n",
    "        model = TemporalRelationClassification(config=config)\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=model_final_name,\n",
    "            learning_rate=3e-5,\n",
    "            per_device_train_batch_size=32,\n",
    "            per_device_eval_batch_size=32,\n",
    "            weight_decay=0.01,\n",
    "            num_train_epochs=10,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"no\",\n",
    "            optim='adamw_torch',\n",
    "            report_to=[],\n",
    "            use_mps_device=True\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_datasets[\"train\"],\n",
    "            eval_dataset=tokenized_datasets[\"test\"],\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=data_collator,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "        trainer.train()\n",
    "        eval_mode = True\n",
    "        print('Evaluate:', model_final_name)\n",
    "        trainer.evaluate(tokenized_datasets['test'])\n",
    "        eval_mode = False\n",
    "        config.register_for_auto_class()\n",
    "        model.register_for_auto_class('AutoModelForSequenceClassification')\n",
    "        # trainer.push_to_hub()\n",
    "        trainer.save_model(model_final_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
